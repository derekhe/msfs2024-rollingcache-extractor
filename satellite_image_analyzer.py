#!/usr/bin/env python3
"""
MSFS2024 RollingCache å«æ˜Ÿå›¾åƒä¸“é¡¹åˆ†æå™¨
ä¸“é—¨æœç´¢4000+ä¸ª256x256å›¾åƒï¼Œæ”¾å®½éªŒè¯æ¡ä»¶
"""

import os
import mmap
import struct
from typing import Dict, List, Tuple, Optional
import argparse
import time
from collections import defaultdict


def find_all_potential_images(file_path: str, target_size: Tuple[int, int] = (256, 256)) -> Dict:
    """æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„256x256å›¾åƒï¼ŒåŒ…æ‹¬å„ç§æ ¼å¼å’Œå˜ä½“"""
    print(f"å«æ˜Ÿå›¾åƒä¸“é¡¹æœç´¢: {os.path.basename(file_path)}")
    print(f"ç›®æ ‡å°ºå¯¸: {target_size[0]}x{target_size[1]}")
    start_time = time.time()
    
    results = {
        'file_path': file_path,
        'potential_images': [],
        'format_analysis': defaultdict(list),
        'size_analysis': defaultdict(list),
        'total_found': 0
    }
    
    target_width, target_height = target_size
    file_size = os.path.getsize(file_path)
    
    # æ‰©å±•çš„å›¾åƒæ ¼å¼ç­¾åå’ŒéªŒè¯
    image_patterns = [
        # PNG å˜ä½“ - æ”¾å®½éªŒè¯
        {
            'name': 'PNG_STANDARD',
            'signature': b'\x89PNG\r\n\x1a\n',
            'validator': lambda data, pos: validate_png_relaxed(data, pos, target_size)
        },
        # PNG chunkå¼€å§‹æ¨¡å¼ (å¯èƒ½PNGå¤´éƒ¨è¢«ä¿®æ”¹)
        {
            'name': 'PNG_IHDR',
            'signature': b'IHDR',
            'validator': lambda data, pos: validate_ihdr_chunk(data, pos, target_size)
        },
        # JPEG å˜ä½“
        {
            'name': 'JPEG_STANDARD',
            'signature': b'\xFF\xD8\xFF',
            'validator': lambda data, pos: validate_jpeg_relaxed(data, pos, target_size)
        },
        # DDS
        {
            'name': 'DDS',
            'signature': b'DDS ',
            'validator': lambda data, pos: validate_dds_relaxed(data, pos, target_size)
        },
        # åŸå§‹å›¾åƒæ•°æ®æ¨¡å¼ - æŸ¥æ‰¾256x256çš„ç»´åº¦æ ‡è¯†
        {
            'name': 'RAW_DIMENSION',
            'signature': struct.pack('<II', target_width, target_height),  # å°ç«¯åºçš„256, 256
            'validator': lambda data, pos: validate_raw_dimensions(data, pos, target_size)
        },
        {
            'name': 'RAW_DIMENSION_BE',
            'signature': struct.pack('>II', target_width, target_height),  # å¤§ç«¯åºçš„256, 256
            'validator': lambda data, pos: validate_raw_dimensions(data, pos, target_size)
        },
        # å¯èƒ½çš„çº¹ç†æ ¼å¼
        {
            'name': 'TEX_HEADER',
            'signature': b'TEX\x00',
            'validator': lambda data, pos: validate_texture_header(data, pos, target_size)
        },
        # BCå‹ç¼©æ ¼å¼
        {
            'name': 'BC_COMPRESSED',
            'signature': b'BC',
            'validator': lambda data, pos: validate_bc_texture(data, pos, target_size)
        }
    ]
    
    with open(file_path, 'rb') as f:
        with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:
            
            for pattern in image_patterns:
                print(f"\næœç´¢ {pattern['name']} æ ¼å¼...")
                signature = pattern['signature']
                validator = pattern['validator']
                
                pos = 0
                format_count = 0
                
                while pos < file_size and format_count < 2000:  # æ¯ç§æ ¼å¼æœ€å¤šæ‰¾2000ä¸ª
                    pos = mm.find(signature, pos)
                    if pos == -1:
                        break
                    
                    # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆå›¾åƒ
                    validation_result = validator(mm, pos)
                    
                    if validation_result:
                        image_info = {
                            'format': pattern['name'],
                            'offset': pos,
                            'signature_pos': pos,
                            **validation_result
                        }
                        
                        results['potential_images'].append(image_info)
                        results['format_analysis'][pattern['name']].append(image_info)
                        
                        # æŒ‰å°ºå¯¸åˆ†ç±»
                        if 'width' in validation_result and 'height' in validation_result:
                            size_key = f"{validation_result['width']}x{validation_result['height']}"
                            results['size_analysis'][size_key].append(image_info)
                        
                        format_count += 1
                        
                        if format_count % 100 == 0:
                            print(f"  æ‰¾åˆ° {format_count} ä¸ª {pattern['name']}")
                    
                    pos += len(signature)
                
                print(f"  {pattern['name']}: æ€»è®¡ {format_count} ä¸ª")
    
    results['total_found'] = len(results['potential_images'])
    results['analysis_time'] = time.time() - start_time
    
    print(f"\næœç´¢å®Œæˆï¼Œè€—æ—¶: {results['analysis_time']:.2f} ç§’")
    print(f"æ€»è®¡æ‰¾åˆ°æ½œåœ¨å›¾åƒ: {results['total_found']} ä¸ª")
    
    return results


def validate_png_relaxed(data: bytes, pos: int, target_size: Tuple[int, int]) -> Optional[Dict]:
    """æ”¾å®½çš„PNGéªŒè¯"""
    if pos + 33 > len(data):
        return None
    
    # æ£€æŸ¥PNGç­¾å
    if data[pos:pos+8] != b'\x89PNG\r\n\x1a\n':
        return None
    
    # æŸ¥æ‰¾IHDR
    ihdr_pos = pos + 8
    for i in range(3):  # å…è®¸ä¸€äº›åç§»
        check_pos = ihdr_pos + i * 4
        if check_pos + 21 <= len(data):
            if data[check_pos+4:check_pos+8] == b'IHDR':
                try:
                    ihdr_data = data[check_pos+8:check_pos+21]
                    width, height, bit_depth, color_type = struct.unpack('>IIBBB', ihdr_data[:9])
                    
                    # æ”¾å®½å°ºå¯¸è¦æ±‚ - æ¥å—256x256æˆ–ç›¸è¿‘å°ºå¯¸
                    if (240 <= width <= 280 and 240 <= height <= 280 and
                        bit_depth in [1, 2, 4, 8, 16] and
                        color_type in [0, 2, 3, 4, 6]):
                        
                        return {
                            'width': width,
                            'height': height,
                            'bit_depth': bit_depth,
                            'color_type': color_type,
                            'estimated_size': estimate_png_size(width, height, bit_depth, color_type)
                        }
                except:
                    continue
    
    return None


def validate_ihdr_chunk(data: bytes, pos: int, target_size: Tuple[int, int]) -> Optional[Dict]:
    """éªŒè¯IHDR chunkï¼ˆå¯èƒ½PNGå¤´éƒ¨è¢«å‰¥ç¦»ï¼‰"""
    if pos + 13 > len(data):
        return None
    
    # æ£€æŸ¥å‰é¢æ˜¯å¦æœ‰é•¿åº¦å­—æ®µ
    for offset in [-8, -4, 0]:
        check_pos = pos + offset
        if check_pos >= 0 and check_pos + 21 <= len(data):
            try:
                if data[check_pos+4:check_pos+8] == b'IHDR':
                    ihdr_data = data[check_pos+8:check_pos+21]
                    width, height, bit_depth, color_type = struct.unpack('>IIBBB', ihdr_data[:9])
                    
                    if (200 <= width <= 300 and 200 <= height <= 300):
                        return {
                            'width': width,
                            'height': height,
                            'bit_depth': bit_depth,
                            'color_type': color_type,
                            'estimated_size': estimate_png_size(width, height, bit_depth, color_type)
                        }
            except:
                continue
    
    return None


def validate_jpeg_relaxed(data: bytes, pos: int, target_size: Tuple[int, int]) -> Optional[Dict]:
    """æ”¾å®½çš„JPEGéªŒè¯"""
    if pos + 20 > len(data):
        return None
    
    # åŸºæœ¬JPEGç­¾åæ£€æŸ¥
    if data[pos:pos+3] != b'\xFF\xD8\xFF':
        return None
    
    # æŸ¥æ‰¾SOFæ ‡è®°æ¥è·å–å°ºå¯¸
    search_end = min(pos + 1024, len(data))
    for i in range(pos + 3, search_end - 10):
        if data[i] == 0xFF and data[i+1] in [0xC0, 0xC1, 0xC2]:  # SOF markers
            try:
                length = struct.unpack('>H', data[i+2:i+4])[0]
                if i + 4 + length <= len(data):
                    height = struct.unpack('>H', data[i+5:i+7])[0]
                    width = struct.unpack('>H', data[i+7:i+9])[0]
                    
                    if 200 <= width <= 300 and 200 <= height <= 300:
                        return {
                            'width': width,
                            'height': height,
                            'estimated_size': width * height * 3  # ä¼°ç®—RGBå¤§å°
                        }
            except:
                continue
    
    return None


def validate_dds_relaxed(data: bytes, pos: int, target_size: Tuple[int, int]) -> Optional[Dict]:
    """DDSæ ¼å¼éªŒè¯"""
    if pos + 128 > len(data):
        return None
    
    if data[pos:pos+4] != b'DDS ':
        return None
    
    try:
        # DDS header
        header_size = struct.unpack('<I', data[pos+4:pos+8])[0]
        if header_size == 124:
            height = struct.unpack('<I', data[pos+12:pos+16])[0]
            width = struct.unpack('<I', data[pos+16:pos+20])[0]
            
            if 200 <= width <= 300 and 200 <= height <= 300:
                return {
                    'width': width,
                    'height': height,
                    'estimated_size': width * height * 4  # ä¼°ç®—RGBAå¤§å°
                }
    except:
        pass
    
    return None


def validate_raw_dimensions(data: bytes, pos: int, target_size: Tuple[int, int]) -> Optional[Dict]:
    """éªŒè¯åŸå§‹ç»´åº¦æ•°æ®"""
    if pos + 8 > len(data):
        return None
    
    try:
        # æ£€æŸ¥æ˜¯å¦çœŸçš„æ˜¯ç»´åº¦æ•°æ®
        width, height = struct.unpack('<II', data[pos:pos+8])
        
        # æ›´å®½æ¾çš„å°ºå¯¸éªŒè¯
        if 200 <= width <= 400 and 200 <= height <= 400:
            # æ£€æŸ¥åç»­æ˜¯å¦æœ‰åˆç†çš„å›¾åƒæ•°æ®
            expected_size = width * height
            if pos + 8 + expected_size <= len(data):
                # ç®€å•çš„æ•°æ®ç†µæ£€æŸ¥
                sample_data = data[pos+8:pos+8+min(1024, expected_size)]
                if len(set(sample_data)) > 10:  # æ•°æ®æœ‰ä¸€å®šå˜åŒ–
                    return {
                        'width': width,
                        'height': height,
                        'estimated_size': expected_size,
                        'format_hint': 'raw_grayscale' if expected_size == width * height else 'raw_rgba'
                    }
    except:
        pass
    
    return None


def validate_texture_header(data: bytes, pos: int, target_size: Tuple[int, int]) -> Optional[Dict]:
    """éªŒè¯è‡ªå®šä¹‰çº¹ç†å¤´éƒ¨"""
    if pos + 32 > len(data):
        return None
    
    # ç®€å•çš„çº¹ç†å¤´éƒ¨å¯å‘å¼æ£€æŸ¥
    try:
        # æ£€æŸ¥åç»­å‡ ä¸ªDWORDæ˜¯å¦åŒ…å«åˆç†çš„ç»´åº¦
        for offset in range(4, 32, 4):
            if pos + offset + 8 <= len(data):
                width, height = struct.unpack('<II', data[pos+offset:pos+offset+8])
                if 200 <= width <= 400 and 200 <= height <= 400:
                    return {
                        'width': width,
                        'height': height,
                        'estimated_size': width * height * 4,
                        'format_hint': 'custom_texture'
                    }
    except:
        pass
    
    return None


def validate_bc_texture(data: bytes, pos: int, target_size: Tuple[int, int]) -> Optional[Dict]:
    """éªŒè¯BCå‹ç¼©çº¹ç†"""
    if pos + 16 > len(data):
        return None
    
    # BCçº¹ç†çš„åŸºæœ¬å¯å‘å¼æ£€æŸ¥
    if data[pos:pos+2] == b'BC':
        # BC1, BC3, BC5, BC7 ç­‰
        bc_type = data[pos+2]
        if bc_type in [ord('1'), ord('3'), ord('5'), ord('7')]:
            # å‡è®¾æ˜¯256x256çš„BCçº¹ç†
            width, height = target_size
            return {
                'width': width,
                'height': height,
                'estimated_size': (width * height) // (2 if bc_type == ord('1') else 1),
                'format_hint': f'BC{chr(bc_type)}'
            }
    
    return None


def estimate_png_size(width: int, height: int, bit_depth: int, color_type: int) -> int:
    """ä¼°ç®—PNGæ–‡ä»¶å¤§å°"""
    # åŸºæœ¬åƒç´ æ•°æ®å¤§å°
    if color_type == 0:  # Grayscale
        raw_size = width * height * (bit_depth // 8 or 1)
    elif color_type == 2:  # RGB
        raw_size = width * height * 3 * (bit_depth // 8 or 1)
    elif color_type == 3:  # Palette
        raw_size = width * height * (bit_depth // 8 or 1)
    elif color_type == 4:  # Grayscale + Alpha
        raw_size = width * height * 2 * (bit_depth // 8 or 1)
    elif color_type == 6:  # RGB + Alpha
        raw_size = width * height * 4 * (bit_depth // 8 or 1)
    else:
        raw_size = width * height * 4
    
    # è€ƒè™‘PNGå‹ç¼©ï¼ˆé€šå¸¸èƒ½å‹ç¼©åˆ°50-70%ï¼‰
    return int(raw_size * 0.6) + 1000  # åŠ ä¸Šå¤´éƒ¨å¼€é”€


def analyze_results(results: Dict) -> None:
    """åˆ†ææœç´¢ç»“æœ"""
    print("\n" + "="*80)
    print("å«æ˜Ÿå›¾åƒåˆ†æç»“æœ")
    print("="*80)
    
    total = results['total_found']
    print(f"æ€»è®¡æ‰¾åˆ°å›¾åƒ: {total}")
    
    if total == 0:
        return
    
    # æŒ‰æ ¼å¼ç»Ÿè®¡
    print(f"\nğŸ“Š æ ¼å¼åˆ†å¸ƒ:")
    for format_name, images in results['format_analysis'].items():
        count = len(images)
        percentage = count / total * 100
        print(f"  {format_name:<20}: {count:>6} ä¸ª ({percentage:>5.1f}%)")
    
    # æŒ‰å°ºå¯¸ç»Ÿè®¡
    print(f"\nğŸ“ å°ºå¯¸åˆ†å¸ƒ:")
    for size_name, images in results['size_analysis'].items():
        count = len(images)
        percentage = count / total * 100
        print(f"  {size_name:<12}: {count:>6} ä¸ª ({percentage:>5.1f}%)")
    
    # æ˜¾ç¤ºä¸€äº›æ ·æœ¬
    print(f"\nğŸ” å‰20ä¸ªå›¾åƒæ ·æœ¬:")
    for i, img in enumerate(results['potential_images'][:20]):
        width = img.get('width', '?')
        height = img.get('height', '?')
        size = img.get('estimated_size', '?')
        print(f"  {i+1:2d}. {img['format']:<20} {width}x{height} @ 0x{img['offset']:08X} (~{size} bytes)")


def extract_samples(file_path: str, results: Dict, output_dir: str = "satellite_samples") -> None:
    """æå–æ ·æœ¬å›¾åƒ"""
    if not results['potential_images']:
        return
    
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    print(f"\næå–æ ·æœ¬åˆ°: {output_dir}")
    
    # é€‰æ‹©ä¸åŒæ ¼å¼çš„æ ·æœ¬
    samples_per_format = 3
    extracted_count = 0
    
    with open(file_path, 'rb') as f:
        with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:
            
            for format_name, images in results['format_analysis'].items():
                format_count = 0
                
                for img in images:
                    if format_count >= samples_per_format:
                        break
                    
                    try:
                        offset = img['offset']
                        est_size = img.get('estimated_size', 50000)
                        
                        # é™åˆ¶æå–å¤§å°
                        max_extract_size = min(est_size * 2, 1024 * 1024)  # æœ€å¤§1MB
                        
                        if offset + max_extract_size <= len(mm):
                            data = mm[offset:offset+max_extract_size]
                            
                            # ç¡®å®šæ–‡ä»¶æ‰©å±•å
                            if 'PNG' in format_name:
                                ext = '.png'
                            elif 'JPEG' in format_name:
                                ext = '.jpg'
                            elif 'DDS' in format_name:
                                ext = '.dds'
                            else:
                                ext = '.bin'
                            
                            width = img.get('width', 'unk')
                            height = img.get('height', 'unk')
                            filename = f"{format_name}_{format_count+1}_{width}x{height}_{hex(offset)}{ext}"
                            filepath = os.path.join(output_dir, filename)
                            
                            with open(filepath, 'wb') as out_f:
                                out_f.write(data)
                            
                            print(f"  âœ“ {filename} ({len(data)} bytes)")
                            format_count += 1
                            extracted_count += 1
                    
                    except Exception as e:
                        print(f"  âœ— æå–å¤±è´¥: {e}")
    
    print(f"æ€»è®¡æå–: {extracted_count} ä¸ªæ ·æœ¬")


def main():
    parser = argparse.ArgumentParser(description='MSFS2024 å«æ˜Ÿå›¾åƒä¸“é¡¹åˆ†æå™¨')
    parser.add_argument('files', nargs='+', help='è¦åˆ†æçš„ CCC æ–‡ä»¶')
    parser.add_argument('--extract', action='store_true', help='æå–æ ·æœ¬å›¾åƒ')
    parser.add_argument('--target-size', nargs=2, type=int, default=[256, 256], 
                       help='ç›®æ ‡å›¾åƒå°ºå¯¸ (é»˜è®¤: 256 256)')
    parser.add_argument('--output-dir', default='satellite_samples', help='æ ·æœ¬è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    target_size = tuple(args.target_size)
    
    for file_path in args.files:
        if not os.path.exists(file_path):
            print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ - {file_path}")
            continue
        
        results = find_all_potential_images(file_path, target_size)
        analyze_results(results)
        
        if args.extract:
            extract_samples(file_path, results, args.output_dir)
        
        print("\n" + "="*80 + "\n")


if __name__ == "__main__":
    main()
